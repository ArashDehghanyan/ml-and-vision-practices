{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save_and_load_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBw95xRu19/Pomjk12XTHT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArashDehghanyan/ml-practicres/blob/main/Save_and_load_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup\n",
        "##Installs and imports"
      ],
      "metadata": {
        "id": "7cdvWFA37vO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTnK5QI87j1w",
        "outputId": "2c0335c3-ad53-42eb-8acc-ceff06cf475a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install pyyaml h5py   # Required to save models in HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud4ipZaw-UGa",
        "outputId": "9fe4a381-b191-4372-9cd0-b9fc83653482"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.\n",
        "train_labels = train_labels[:1000]\n",
        "\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_labels = test_labels[:1000]"
      ],
      "metadata": {
        "id": "5qT3CRp6-nSE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define a model\n",
        "##Start by a simple Sequential model"
      ],
      "metadata": {
        "id": "6Xi45jqJAHtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    # Define model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(10)\n",
        "    ])\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(0.001),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create a basic model instance\n",
        "basic_model = create_model()\n",
        "\n",
        "# Display the model architecture\n",
        "basic_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWxMB-vp_m7f",
        "outputId": "15e189bd-37bd-4c8e-e7d8-69c9916973c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save checkpoints during training"
      ],
      "metadata": {
        "id": "SigT_izfHrNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"training_1/checkpoint.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weight\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only=True)\n",
        "\n",
        "# Train model with new callback\n",
        "basic_model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    # Pass callback to training\n",
        "    callbacks=[checkpoint_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRaeyLHdIHPK",
        "outputId": "9811b731-c471-41a1-b59a-8fdad92496a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 1.3224 - sparse_categorical_accuracy: 0.6406\n",
            "Epoch 1: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1339 - sparse_categorical_accuracy: 0.6860 - val_loss: 0.6828 - val_sparse_categorical_accuracy: 0.7860\n",
            "Epoch 2/10\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.4144 - sparse_categorical_accuracy: 0.8777\n",
            "Epoch 2: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4079 - sparse_categorical_accuracy: 0.8830 - val_loss: 0.5373 - val_sparse_categorical_accuracy: 0.8330\n",
            "Epoch 3/10\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.2746 - sparse_categorical_accuracy: 0.9332\n",
            "Epoch 3: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2813 - sparse_categorical_accuracy: 0.9310 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.8560\n",
            "Epoch 4/10\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.2270 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 4: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2137 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.4676 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 5/10\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1569 - sparse_categorical_accuracy: 0.9667\n",
            "Epoch 5: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1564 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.8550\n",
            "Epoch 6/10\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.1036 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 6: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.4223 - val_sparse_categorical_accuracy: 0.8640\n",
            "Epoch 7/10\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0943 - sparse_categorical_accuracy: 0.9851\n",
            "Epoch 7: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0928 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.4544 - val_sparse_categorical_accuracy: 0.8590\n",
            "Epoch 8/10\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0642 - sparse_categorical_accuracy: 0.9946\n",
            "Epoch 8: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8670\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0476 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 9: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4014 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 10/10\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0374 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0380 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4275 - val_sparse_categorical_accuracy: 0.8680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d4f4ac3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MtPP6SvXECr",
        "outputId": "03cda6a1-c1f0-4d77-9f10-5994eb79a42a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['checkpoint', 'checkpoint.ckpt.data-00000-of-00001', 'checkpoint.ckpt.index']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create an untrained model and evalute it on the test set"
      ],
      "metadata": {
        "id": "1eqc486hX5B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "untrained_model = create_model()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = untrained_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Untrained model accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_CvZvq3Xl_q",
        "outputId": "82e9749a-8a7a-40c6-d7b6-bb8338592c24"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 0s - loss: 2.3227 - sparse_categorical_accuracy: 0.0970 - 177ms/epoch - 6ms/step\n",
            "Untrained model accuracy:  9.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load weights from checkpoint and re-evaluate the model"
      ],
      "metadata": {
        "id": "ZSTF86fCcGqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights\n",
        "untrained_model.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = untrained_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp1u8rDGbdjL",
        "outputId": "e8ef4ba1-6b19-4a51-e943-b36ee07fbcaa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 0s - loss: 0.4275 - sparse_categorical_accuracy: 0.8680 - 89ms/epoch - 3ms/step\n",
            "Restored model accuracy: 86.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checkpoint options"
      ],
      "metadata": {
        "id": "EbFY0uNCdR1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Include the epoch in the filename\n",
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create a callback to save model's weight every 5 epochs\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq=5*batch_size\n",
        ")\n",
        "\n",
        "# Create a new model instance\n",
        "new_model = create_model()\n",
        "\n",
        "# Save the weights using (checkpoint_path) format\n",
        "new_model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "# Train the model with new callback\n",
        "new_model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=50,\n",
        "    verbose=1, \n",
        "    callbacks=[cp_callback],\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(test_images, test_labels)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwt6Hjtc_dn",
        "outputId": "ea4b1c8c-f6fd-4fd6-9c21-01c72a537340"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 1s 13ms/step - loss: 1.1767 - sparse_categorical_accuracy: 0.6530 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4336 - sparse_categorical_accuracy: 0.8800 - val_loss: 0.5162 - val_sparse_categorical_accuracy: 0.8360\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2841 - sparse_categorical_accuracy: 0.9230 - val_loss: 0.4731 - val_sparse_categorical_accuracy: 0.8500\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2141 - sparse_categorical_accuracy: 0.9420 - val_loss: 0.4821 - val_sparse_categorical_accuracy: 0.8430\n",
            "Epoch 5/50\n",
            "21/32 [==================>...........] - ETA: 0s - loss: 0.1719 - sparse_categorical_accuracy: 0.9568\n",
            "Epoch 5: saving model to training_2/cp-0005.ckpt\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1716 - sparse_categorical_accuracy: 0.9610 - val_loss: 0.4236 - val_sparse_categorical_accuracy: 0.8650\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1160 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8600\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0811 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.4054 - val_sparse_categorical_accuracy: 0.8720\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0635 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.4061 - val_sparse_categorical_accuracy: 0.8680\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0484 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.3944 - val_sparse_categorical_accuracy: 0.8710\n",
            "Epoch 10/50\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0357 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10: saving model to training_2/cp-0010.ckpt\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0356 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4029 - val_sparse_categorical_accuracy: 0.8720\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0272 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4146 - val_sparse_categorical_accuracy: 0.8670\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4039 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0216 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4000 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0170 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4068 - val_sparse_categorical_accuracy: 0.8660\n",
            "Epoch 15/50\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0139 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15: saving model to training_2/cp-0015.ckpt\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.0143 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0168 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4057 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0113 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4120 - val_sparse_categorical_accuracy: 0.8810\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0101 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4291 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0083 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4200 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 20/50\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0071 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20: saving model to training_2/cp-0020.ckpt\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0076 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4293 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0068 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4270 - val_sparse_categorical_accuracy: 0.8720\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0061 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0062 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.8700\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0053 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4350 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 25/50\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0052 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25: saving model to training_2/cp-0025.ckpt\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0049 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4587 - val_sparse_categorical_accuracy: 0.8690\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0045 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4282 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0043 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4491 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0039 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0038 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 30/50\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0039 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30: saving model to training_2/cp-0030.ckpt\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0039 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4481 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0031 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4565 - val_sparse_categorical_accuracy: 0.8770\n",
            "Epoch 35/50\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0026 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35: saving model to training_2/cp-0035.ckpt\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0026 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4531 - val_sparse_categorical_accuracy: 0.8770\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0026 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4689 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4592 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4537 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4586 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 40/50\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0019 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40: saving model to training_2/cp-0040.ckpt\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4650 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4674 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4779 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 45/50\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45: saving model to training_2/cp-0045.ckpt\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4748 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4720 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4909 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4802 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4810 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 50/50\n",
            "21/32 [==================>...........] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50: saving model to training_2/cp-0050.ckpt\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.8850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d4a1d6490>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoG-Yz_7jGDf",
        "outputId": "f34f3135-8ada-4db5-f8c6-31b884d618de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp-0035.ckpt.index',\n",
              " 'cp-0015.ckpt.index',\n",
              " 'checkpoint',\n",
              " 'cp-0000.ckpt.data-00000-of-00001',\n",
              " 'cp-0000.ckpt.index',\n",
              " 'cp-0005.ckpt.index',\n",
              " 'cp-0040.ckpt.data-00000-of-00001',\n",
              " 'cp-0025.ckpt.index',\n",
              " 'cp-0030.ckpt.data-00000-of-00001',\n",
              " 'cp-0020.ckpt.index',\n",
              " 'cp-0015.ckpt.data-00000-of-00001',\n",
              " 'cp-0025.ckpt.data-00000-of-00001',\n",
              " 'cp-0040.ckpt.index',\n",
              " 'cp-0020.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.index',\n",
              " 'cp-0045.ckpt.index',\n",
              " 'cp-0035.ckpt.data-00000-of-00001',\n",
              " 'cp-0010.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.data-00000-of-00001',\n",
              " 'cp-0005.ckpt.data-00000-of-00001',\n",
              " 'cp-0010.ckpt.index',\n",
              " 'cp-0045.ckpt.data-00000-of-00001',\n",
              " 'cp-0030.ckpt.index']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the latest checkpoint\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HY27knSQjm8f",
        "outputId": "aa3fce39-0899-4db3-e48d-f2613de08a50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model instance\n",
        "new_untrained_model = create_model()\n",
        "\n",
        "# Load previously saved weights\n",
        "new_untrained_model.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = new_untrained_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model accuracy: {:5.2f}%\".format(acc * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btzP6Ys7kY5f",
        "outputId": "9dd3b336-e8fb-4a96-de5c-6841759f2a30"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 0s - loss: 0.4706 - sparse_categorical_accuracy: 0.8850 - 190ms/epoch - 6ms/step\n",
            "Restored model accuracy: 88.50%\n"
          ]
        }
      ]
    }
  ]
}