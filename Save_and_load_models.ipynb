{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save_and_load_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdABexyzl0E1lizhAjRR94",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArashDehghanyan/ml-practicres/blob/main/Save_and_load_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup\n",
        "##Installs and imports"
      ],
      "metadata": {
        "id": "7cdvWFA37vO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTnK5QI87j1w",
        "outputId": "107ec136-fb28-4233-d318-9853e4971aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install pyyaml h5py   # Required to save models in HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud4ipZaw-UGa",
        "outputId": "3982d300-fcf4-4027-e9d7-cef55eb580ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.\n",
        "train_labels = train_labels[:1000]\n",
        "\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_labels = test_labels[:1000]"
      ],
      "metadata": {
        "id": "5qT3CRp6-nSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd1c891-5440-455f-ad70-f0eb56f67642"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define a model\n",
        "##Start by a simple Sequential model"
      ],
      "metadata": {
        "id": "6Xi45jqJAHtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    # Define model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(10)\n",
        "    ])\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(0.001),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create a basic model instance\n",
        "basic_model = create_model()\n",
        "\n",
        "# Display the model architecture\n",
        "basic_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWxMB-vp_m7f",
        "outputId": "7f4b5173-86fd-4dab-88f8-0d3c8bdefdea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save checkpoints during training"
      ],
      "metadata": {
        "id": "SigT_izfHrNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"training_1/checkpoint.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weight\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only=True)\n",
        "\n",
        "# Train model with new callback\n",
        "basic_model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    # Pass callback to training\n",
        "    callbacks=[checkpoint_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRaeyLHdIHPK",
        "outputId": "bdd933ab-ba6f-4c62-9a2c-7f15038240c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 1.2099 - sparse_categorical_accuracy: 0.6674\n",
            "Epoch 1: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 1s 12ms/step - loss: 1.1300 - sparse_categorical_accuracy: 0.6920 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.7960\n",
            "Epoch 2/10\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.4247 - sparse_categorical_accuracy: 0.8772\n",
            "Epoch 2: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4153 - sparse_categorical_accuracy: 0.8780 - val_loss: 0.5201 - val_sparse_categorical_accuracy: 0.8420\n",
            "Epoch 3/10\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.2776 - sparse_categorical_accuracy: 0.9297\n",
            "Epoch 3: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2835 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.4718 - val_sparse_categorical_accuracy: 0.8500\n",
            "Epoch 4/10\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2051 - sparse_categorical_accuracy: 0.9479\n",
            "Epoch 4: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9470 - val_loss: 0.4383 - val_sparse_categorical_accuracy: 0.8570\n",
            "Epoch 5/10\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1466 - sparse_categorical_accuracy: 0.9752\n",
            "Epoch 5: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1461 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.4387 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 6/10\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1148 - sparse_categorical_accuracy: 0.9795\n",
            "Epoch 6: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1117 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.4211 - val_sparse_categorical_accuracy: 0.8600\n",
            "Epoch 7/10\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0876 - sparse_categorical_accuracy: 0.9873\n",
            "Epoch 7: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0854 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.4348 - val_sparse_categorical_accuracy: 0.8620\n",
            "Epoch 8/10\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0667 - sparse_categorical_accuracy: 0.9903\n",
            "Epoch 8: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.4036 - val_sparse_categorical_accuracy: 0.8700\n",
            "Epoch 9/10\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0490 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 9: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.4070 - val_sparse_categorical_accuracy: 0.8630\n",
            "Epoch 10/10\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0428 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 10: saving model to training_1/checkpoint.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0424 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.4038 - val_sparse_categorical_accuracy: 0.8720\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7febc5ae87d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MtPP6SvXECr",
        "outputId": "4fba1dda-9bc9-465a-870a-b188dff8a101"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['checkpoint', 'checkpoint.ckpt.data-00000-of-00001', 'checkpoint.ckpt.index']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create an untrained model and evalute it on the test set"
      ],
      "metadata": {
        "id": "1eqc486hX5B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "untrained_model = create_model()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = untrained_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Untrained model accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_CvZvq3Xl_q",
        "outputId": "3af3eacd-3fb8-485c-9560-74364a2e7afc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 0s - loss: 2.3820 - sparse_categorical_accuracy: 0.0930 - 156ms/epoch - 5ms/step\n",
            "Untrained model accuracy:  9.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load weights from checkpoint and re-evaluate the model"
      ],
      "metadata": {
        "id": "ZSTF86fCcGqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights\n",
        "untrained_model.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = untrained_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp1u8rDGbdjL",
        "outputId": "6f3bd94a-6ba8-4f9b-e4b8-28d5b8f7bdce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 0s - loss: 0.4038 - sparse_categorical_accuracy: 0.8720 - 68ms/epoch - 2ms/step\n",
            "Restored model accuracy: 87.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checkpoint options"
      ],
      "metadata": {
        "id": "EbFY0uNCdR1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Include the epoch in the filename\n",
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create a callback to save model's weight every 5 epochs\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq=5*batch_size\n",
        ")\n",
        "\n",
        "# Create a new model instance\n",
        "new_model = create_model()\n",
        "\n",
        "# Save the weights using (checkpoint_path) format\n",
        "new_model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "# Train the model with new callback\n",
        "new_model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=50,\n",
        "    verbose=1, \n",
        "    callbacks=[cp_callback],\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(test_images, test_labels)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwt6Hjtc_dn",
        "outputId": "0bb29bd7-2e7b-468a-e97e-aa6d2e23729d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 1s 10ms/step - loss: 1.1695 - sparse_categorical_accuracy: 0.6760 - val_loss: 0.7257 - val_sparse_categorical_accuracy: 0.7830\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4272 - sparse_categorical_accuracy: 0.8740 - val_loss: 0.5582 - val_sparse_categorical_accuracy: 0.8240\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2917 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.4801 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2193 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.4263 - val_sparse_categorical_accuracy: 0.8680\n",
            "Epoch 5/50\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1576 - sparse_categorical_accuracy: 0.9664\n",
            "Epoch 5: saving model to training_2/cp-0005.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1628 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.4214 - val_sparse_categorical_accuracy: 0.8690\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1154 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.4429 - val_sparse_categorical_accuracy: 0.8580\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0881 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.4161 - val_sparse_categorical_accuracy: 0.8690\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.4046 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.3971 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 10/50\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0352 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10: saving model to training_2/cp-0010.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0341 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4108 - val_sparse_categorical_accuracy: 0.8660\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0298 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4212 - val_sparse_categorical_accuracy: 0.8650\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0256 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4019 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0205 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4058 - val_sparse_categorical_accuracy: 0.8770\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0176 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4108 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 15/50\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0149 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15: saving model to training_2/cp-0015.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0151 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4057 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0132 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4140 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0124 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4201 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0103 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4260 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0090 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4300 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 20/50\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0092 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20: saving model to training_2/cp-0020.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0091 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4323 - val_sparse_categorical_accuracy: 0.8690\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4338 - val_sparse_categorical_accuracy: 0.8740\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0063 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4305 - val_sparse_categorical_accuracy: 0.8770\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0057 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4372 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0058 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4364 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0045 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25: saving model to training_2/cp-0025.ckpt\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0046 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4398 - val_sparse_categorical_accuracy: 0.8730\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0046 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0041 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4387 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0037 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4473 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0035 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 30/50\n",
            "24/32 [=====================>........] - ETA: 0s - loss: 0.0035 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30: saving model to training_2/cp-0030.ckpt\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0034 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4517 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0034 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4492 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0029 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8850\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0025 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.8850\n",
            "Epoch 35/50\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0025 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35: saving model to training_2/cp-0035.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0025 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4537 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4638 - val_sparse_categorical_accuracy: 0.8770\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4663 - val_sparse_categorical_accuracy: 0.8720\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4641 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4705 - val_sparse_categorical_accuracy: 0.8750\n",
            "Epoch 40/50\n",
            "24/32 [=====================>........] - ETA: 0s - loss: 0.0020 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40: saving model to training_2/cp-0040.ckpt\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4648 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.8810\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.8770\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4769 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 45/50\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0014 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45: saving model to training_2/cp-0045.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4798 - val_sparse_categorical_accuracy: 0.8810\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4806 - val_sparse_categorical_accuracy: 0.8830\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4794 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4766 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4816 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 50/50\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0011 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50: saving model to training_2/cp-0050.ckpt\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4780 - val_sparse_categorical_accuracy: 0.8760\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7febbe95c410>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoG-Yz_7jGDf",
        "outputId": "f4f93f33-dde9-4791-8032-42e4316c1759"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp-0035.ckpt.index',\n",
              " 'cp-0015.ckpt.index',\n",
              " 'checkpoint',\n",
              " 'cp-0000.ckpt.data-00000-of-00001',\n",
              " 'cp-0000.ckpt.index',\n",
              " 'cp-0005.ckpt.index',\n",
              " 'cp-0040.ckpt.data-00000-of-00001',\n",
              " 'cp-0025.ckpt.index',\n",
              " 'cp-0030.ckpt.data-00000-of-00001',\n",
              " 'cp-0020.ckpt.index',\n",
              " 'cp-0015.ckpt.data-00000-of-00001',\n",
              " 'cp-0025.ckpt.data-00000-of-00001',\n",
              " 'cp-0040.ckpt.index',\n",
              " 'cp-0020.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.index',\n",
              " 'cp-0045.ckpt.index',\n",
              " 'cp-0035.ckpt.data-00000-of-00001',\n",
              " 'cp-0010.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.data-00000-of-00001',\n",
              " 'cp-0005.ckpt.data-00000-of-00001',\n",
              " 'cp-0010.ckpt.index',\n",
              " 'cp-0045.ckpt.data-00000-of-00001',\n",
              " 'cp-0030.ckpt.index']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the latest checkpoint\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HY27knSQjm8f",
        "outputId": "7312ae51-bc44-4dfd-e975-e4b036a108f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model instance\n",
        "new_untrained_model = create_model()\n",
        "\n",
        "# Load previously saved weights\n",
        "new_untrained_model.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = new_untrained_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model accuracy: {:5.2f}%\".format(acc * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btzP6Ys7kY5f",
        "outputId": "a0e13dda-4e02-4bd4-eddc-4e3418e40ca1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 0s - loss: 0.4780 - sparse_categorical_accuracy: 0.8760 - 164ms/epoch - 5ms/step\n",
            "Restored model accuracy: 87.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Manually save models"
      ],
      "metadata": {
        "id": "GV9gjT9Vu1jR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights\n",
        "basic_model.save_weights('./checkpoints/my-checkpoints')\n",
        "\n",
        "#  Create model\n",
        "model = create_model()\n",
        "\n",
        "# Restore model\n",
        "model.load_weights(\"./checkpoints/my-checkpoints\")\n",
        "\n",
        "# Evaluate model\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6lBBI20u4ao",
        "outputId": "81f2e439-9faa-47e2-e2e3-9b25bb022dad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 0s - loss: 0.4038 - sparse_categorical_accuracy: 0.8720 - 161ms/epoch - 5ms/step\n",
            "Restored model, accuracy: 87.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SavedModel format"
      ],
      "metadata": {
        "id": "YS5hcFDHxhR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train a new model instance\n",
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Save the rntire model as a savedmodel\n",
        "! mkdir -p saved_model\n",
        "model.save(\"saved_model/my_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5k0xra6xkgH",
        "outputId": "0a58112e-4d99-4d76-afd5-8b34d36c78f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 1.1462 - sparse_categorical_accuracy: 0.6850\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4189 - sparse_categorical_accuracy: 0.8910\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2905 - sparse_categorical_accuracy: 0.9280\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2072 - sparse_categorical_accuracy: 0.9460\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1510 - sparse_categorical_accuracy: 0.9670\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inspect the saved model directory"
      ],
      "metadata": {
        "id": "MUpeuPSAyw_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# contains my_model directory\n",
        "! ls saved_model\n",
        "\n",
        "# Contains assets directory, keras_metadata.pb, saved_model.pb and variables folder.\n",
        "! ls saved_model/my_model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3fIKjxZy1AN",
        "outputId": "ce72a12f-360e-4ab9-ef0f-46520a8c4b6a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_model\n",
            "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reload a fresh keras model"
      ],
      "metadata": {
        "id": "LK4k4d8B0Ilp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = keras.models.load_model(\"saved_model/my_model\")\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_N64zr50MQp",
        "outputId": "28938621-5d8e-49a4-df81-ff89829ece09"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the restored model\n",
        "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
        "\n",
        "\n",
        "print(new_model.predict(test_images).shape)"
      ],
      "metadata": {
        "id": "jguUGjGE0j-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f499cefc-476c-4032-9961-01dc3c7bbf55"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 0s - loss: 0.4469 - sparse_categorical_accuracy: 0.8490 - 153ms/epoch - 5ms/step\n",
            "Restored model, accuracy: 84.90%\n",
            "(1000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##HDF5 format"
      ],
      "metadata": {
        "id": "In4ITv8pnnMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model\n",
        "model = create_model()\n",
        "\n",
        "# Train model\n",
        "model.fit(train_images, train_labels, epochs=5, verbose=1)\n",
        "\n",
        "# Save the whole model to a HDF5 file.\n",
        "# the .h5 extension indicates that file is in HDF5 format.\n",
        "model.save(\"my_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-8WO60MnqVt",
        "outputId": "30a709b3-426e-4520-acd7-14ede371d930"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.1788 - sparse_categorical_accuracy: 0.6690\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8720\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2862 - sparse_categorical_accuracy: 0.9270\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2184 - sparse_categorical_accuracy: 0.9470\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1604 - sparse_categorical_accuracy: 0.9660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the exact same model, including its weights and optimizer\n",
        "new_model = keras.models.load_model(\"my_model.h5\")\n",
        "\n",
        "# Show model structure\n",
        "new_model.summary()\n",
        "\n",
        "# Check its accuracy\n",
        "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model accuracy: {:5.2f}%\".format(100 * acc))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-_UKOQxpOdD",
        "outputId": "fe952cf1-a48e-47ca-b27b-b872b698812f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "32/32 - 0s - loss: 0.4369 - sparse_categorical_accuracy: 0.8680 - 157ms/epoch - 5ms/step\n",
            "Restored model accuracy: 86.80%\n"
          ]
        }
      ]
    }
  ]
}